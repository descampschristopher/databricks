{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bd82c03d-8587-418c-a233-a0cbdac6afee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%run \"/Workspace/Users/descamps.christopher@gmail.com/databricks/Other/common\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b21f2eef-7eab-42fb-8850-035603839112",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Read traffic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cd8cb86c-3b1f-48e3-885d-b0f6be934162",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def read_Traffic_Data():\n",
    "    from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType\n",
    "    from pyspark.sql.functions import current_timestamp\n",
    "    print(\"Reading the Raw Traffic Data :  \", end='')\n",
    "    schematraffic = StructType([\n",
    "    StructField(\"Record_ID\",IntegerType()),\n",
    "    StructField(\"Count_point_id\",IntegerType()),\n",
    "    StructField(\"Direction_of_travel\",StringType()),\n",
    "    StructField(\"Year\",IntegerType()),\n",
    "    StructField(\"Count_date\",StringType()),\n",
    "    StructField(\"hour\",IntegerType()),\n",
    "    StructField(\"Region_id\",IntegerType()),\n",
    "    StructField(\"Region_name\",StringType()),\n",
    "    StructField(\"Local_authority_name\",StringType()),\n",
    "    StructField(\"Road_name\",StringType()),\n",
    "    StructField(\"Road_Category_ID\",IntegerType()),\n",
    "    StructField(\"Start_junction_road_name\",StringType()),\n",
    "    StructField(\"End_junction_road_name\",StringType()),\n",
    "    StructField(\"Latitude\",DoubleType()),\n",
    "    StructField(\"Longitude\",DoubleType()),\n",
    "    StructField(\"Link_length_km\",DoubleType()),\n",
    "    StructField(\"Pedal_cycles\",IntegerType()),\n",
    "    StructField(\"Two_wheeled_motor_vehicles\",IntegerType()),\n",
    "    StructField(\"Cars_and_taxis\",IntegerType()),\n",
    "    StructField(\"Buses_and_coaches\",IntegerType()),\n",
    "    StructField(\"LGV_Type\",IntegerType()),\n",
    "    StructField(\"HGV_Type\",IntegerType()),\n",
    "    StructField(\"EV_Car\",IntegerType()),\n",
    "    StructField(\"EV_Bike\",IntegerType())\n",
    "    ])\n",
    "\n",
    "\n",
    "\n",
    "    rawTraffic_stream = (spark.readStream\n",
    "        .format(\"cloudFiles\")\n",
    "        .option(\"cloudFiles.format\",\"csv\")\n",
    "        .option(\"checkpointLocation\", f'{checkpoint_path}')\n",
    "        .option('header','true')\n",
    "        .schema(schematraffic)\n",
    "        .load(f'{landingzone}/raw_traffic/')\n",
    "\n",
    "        .withColumn(\"Extract_Time\", current_timestamp()))\n",
    "    \n",
    "    print('Reading Succcess !!')\n",
    "    print('*******************')\n",
    "\n",
    "    return rawTraffic_stream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "959cd689-f4db-450a-b58c-57a7c9e71050",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## write_Traffic_Data(StreamingDF,environment) Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "275d2631-7215-4258-9f73-27f47ac44124",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def write_Traffic_Data(StreamingDF,environment):\n",
    "    print(f'Writing data to {environment}_catalog raw_traffic table', end='' )\n",
    "    write_Stream = (StreamingDF.writeStream\n",
    "                    .format('delta')\n",
    "                    .option(\"checkpointLocation\",f'{checkpoint_path}/raw_traffic/')\n",
    "                    .outputMode('append')\n",
    "                    .queryName('rawTrafficWriteStream')\n",
    "                    .trigger(availableNow=True)\n",
    "                    .toTable(f\"`{environment}_catalog`.`bronze`.`raw_traffic`\"))\n",
    "    \n",
    "    write_Stream.awaitTermination()\n",
    "    print('Write Success Traffic Data')\n",
    "    print(\"****************************\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "df492715-92ed-4734-b12d-ed7d2926d49d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Read road data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8f6d9dbd-cfe5-4703-9767-a154beb39697",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def read_roads_data():\n",
    "    from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType\n",
    "    from pyspark.sql.functions import current_timestamp\n",
    "    print(\"Reading the Raw Road Data :  \", end='')\n",
    "    schemaroad = StructType([\n",
    "        StructField(\"Road_ID\", IntegerType()),\n",
    "        StructField(\"Road_Category_Id\", IntegerType()),\n",
    "        StructField(\"Road_Category\", StringType()),\n",
    "        StructField(\"Region_ID\", IntegerType()),\n",
    "        StructField(\"Region_Name\", StringType()),\n",
    "        StructField(\"Total_Link_Length_Km\", DoubleType()),\n",
    "        StructField(\"Total_Link_Length_Miles\", DoubleType()),\n",
    "        StructField(\"All_Motor_Vehicles\", DoubleType())\n",
    "    ])\n",
    "\n",
    "\n",
    "    # structureType\n",
    "    rawroads_stream = (spark.readStream\n",
    "        .format(\"cloudFiles\")\n",
    "        .option(\"cloudFiles.format\",\"csv\")\n",
    "        .option(\"checkpointLocation\", f'{checkpoint_path}/raw_roads/')\n",
    "        .option('header','true')\n",
    "        .schema(schemaroad)\n",
    "        .load(f'{landingzone}/raw_roads/')\n",
    "\n",
    "        .withColumn(\"Extract_Time\", current_timestamp()))\n",
    "    \n",
    "    print('Reading Succcess Road Data!')\n",
    "    print('*******************')\n",
    "\n",
    "    return rawroads_stream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f08be084-f65b-40bb-a819-5113e5c12ad7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## write_Road_Data(StreamingDF,environment) Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dc62def0-3253-4f69-8421-716fe5dc4e2b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def write_Road_Data(StreamingDF,environment):\n",
    "    print(f'Writing data to {environment}_catalog raw_road table', end='' )\n",
    "    writeRoads_Stream = (StreamingDF.writeStream\n",
    "                    .format('delta')\n",
    "                    .option(\"checkpointLocation\",f'{checkpoint_path}/raw_roads/')\n",
    "                    #.option(\"cloudFiles.partitionColumns\", \"Region_ID\")\n",
    "                    .outputMode('append')\n",
    "                    .queryName('rawroadsWriteStream')\n",
    "                    .trigger(availableNow=True)\n",
    "                    .toTable(f\"`{environment}_catalog`.`bronze`.`raw_roads`\"))\n",
    "    \n",
    "    writeRoads_Stream.awaitTermination()\n",
    "    print('Write Success Road Data')\n",
    "    print(\"****************************\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "01a25860-ae1b-4e0f-ba76-ca384d271400",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ed012a45-bdb2-4ab7-9395-a90d320c57a2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "Initglobalvarpath(env)\n",
    "read_DF = read_Traffic_Data()\n",
    "write_Traffic_Data(read_DF,env)\n",
    "read_road_DF = read_roads_data()\n",
    "write_Road_Data(read_road_DF,env)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 6408649828465567,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "LoadRawtoBronze",
   "widgets": {
    "env": {
     "currentValue": "dev",
     "nuid": "4197a557-be1b-4817-b208-5eaba9d352d7",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": " Enter the environment in lower case",
      "name": "env",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": " Enter the environment in lower case",
      "name": "env",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
